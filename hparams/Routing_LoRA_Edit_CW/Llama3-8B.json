{
    "model_name": "Llama3-8B",
    "layers": [4, 5, 6, 7, 8],
    "clamp_norm_factor": 0.75,
    "layer_selection": "all",
    "fact_token": "subject_last",
    "v_num_grad_steps": 25,
    "v_lr": 1e-1,
    "v_loss_layer": 31,
    "v_weight_decay": 0.5,
    "kl_factor": 0.0625,
    "mom2_adjustment": true,
    "mom2_update_weight": 15000,
    "rewrite_module_tmp": "model.layers.{}.mlp.down_proj",
    "layer_module_tmp": "model.layers.{}",
    "mlp_module_tmp": "model.layers.{}.mlp",
    "attn_module_tmp": "model.layers.{}.self_attn",
    "ln_f_module": "model.norm",
    "lm_head_module": "lm_head",
    "mom2_dataset": "wikipedia",
    "mom2_n_samples": 100000,
    "mom2_dtype": "float32",
    "nullspace_threshold": 2e-2,
    "L2": 10,
    "lora_rank": 64,
    "routing_mode": "cw",
    "router_rank": 16,
    "router_gamma": 10.0,
    "router_tau_floor": 1e-6,
    "router_neg_quantile": 0.92,
    "router_top_m": 2,
    "router_use_neg_calib": true,
    "router_score_norm": true,
    "router_kbank_max": 1024
}
